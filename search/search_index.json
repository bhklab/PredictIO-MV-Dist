{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Distributed Multivariable Predictive Modelling for Immuno-Oncology Response Authors: Farnoosh Abbas Aghababazadeh , Kewei Ni , Nasim Bondar Sahebi Contact: farnoosh.abbasaghababazadeh@uhn.ca , kewei.ni@uhn.ca , nasim.bondarsahebi@uhn.ca Description: A distributed framework for multivariable predictive modeling of Immuno-Oncology (IO) response, enabling parallelized model training across multiple datasets using Apache Spark, with strict adherence to data privacy. Project Overview This repository implements a distributed Spark-based pipeline for multivariable analysis of immune-related RNA signatures and their predictive power for IO therapy response. Key features include: Center-specific training of XGBoost models with no data sharing Tree-based model aggregation to build a global model Independent model validation using public and private cohorts Reproducible and scalable deployment using Apache Spark and R/SparkR Spark Environment Setup Apache Spark is required for distributed model training. Install Spark: Download and extract Spark 3.2.1 with Hadoop 3.2: https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz Set Spark environment in your R script ( Train_Distributed_XGBoost.r ): r Sys.setenv(SPARK_HOME = \"/your/local/path/spark-3.2.1-bin-hadoop3.2\") .libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\"), .libPaths())) Install required R packages: r install.packages(\"SparkR\") Repository Structure Distributed_XGBoost/ \u251c\u2500\u2500 config/ # Optional YAML configs (not required for MV) \u251c\u2500\u2500 data/ # Raw data, processed objects, results folders \u2502 \u251c\u2500\u2500 rawdata/ \u2502 \u251c\u2500\u2500 procdata/ \u2502 \u2514\u2500\u2500 results/ \u2502 \u251c\u2500\u2500 local/ \u2502 \u251c\u2500\u2500 global/ \u2502 \u2514\u2500\u2500 validation/ \u251c\u2500\u2500 workflow/scripts/ # R and Python scripts for modeling \u2502 \u251c\u2500\u2500 Compute_GeneSigScore.r \u2502 \u251c\u2500\u2500 Create_train_set.r \u2502 \u251c\u2500\u2500 Train_Distributed_XGBoost.r \u2502 \u251c\u2500\u2500 Aggregate_model.py \u2502 \u2514\u2500\u2500 Validate_global_model.r \u251c\u2500\u2500 docs/ # Markdown-based documentation \u251c\u2500\u2500 pixi.toml # Pixi environment specification \u2514\u2500\u2500 README.md # Project overview and setup instructions Set Up Prerequisites Pixi is required to run this project. If you haven't installed it yet, follow these instructions Getting Started Clone and Run git clone https://github.com/bhklab/PredictIO-MV-Dist.git cd PredictIO-MV-Dist Documentation Full documentation will be available in the docs/ folder or via published GitHub Pages. For data download and processing, please refer to the multivariable repository: \ud83d\udd17 https://github.com/bhklab/PredictIO-MV-Dist","title":"Home"},{"location":"#distributed-multivariable-predictive-modelling-for-immuno-oncology-response","text":"Authors: Farnoosh Abbas Aghababazadeh , Kewei Ni , Nasim Bondar Sahebi Contact: farnoosh.abbasaghababazadeh@uhn.ca , kewei.ni@uhn.ca , nasim.bondarsahebi@uhn.ca Description: A distributed framework for multivariable predictive modeling of Immuno-Oncology (IO) response, enabling parallelized model training across multiple datasets using Apache Spark, with strict adherence to data privacy.","title":"Distributed Multivariable Predictive Modelling for Immuno-Oncology Response"},{"location":"#project-overview","text":"This repository implements a distributed Spark-based pipeline for multivariable analysis of immune-related RNA signatures and their predictive power for IO therapy response. Key features include: Center-specific training of XGBoost models with no data sharing Tree-based model aggregation to build a global model Independent model validation using public and private cohorts Reproducible and scalable deployment using Apache Spark and R/SparkR","title":"Project Overview"},{"location":"#spark-environment-setup","text":"Apache Spark is required for distributed model training. Install Spark: Download and extract Spark 3.2.1 with Hadoop 3.2: https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz Set Spark environment in your R script ( Train_Distributed_XGBoost.r ): r Sys.setenv(SPARK_HOME = \"/your/local/path/spark-3.2.1-bin-hadoop3.2\") .libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\"), .libPaths())) Install required R packages: r install.packages(\"SparkR\")","title":"Spark Environment Setup"},{"location":"#repository-structure","text":"Distributed_XGBoost/ \u251c\u2500\u2500 config/ # Optional YAML configs (not required for MV) \u251c\u2500\u2500 data/ # Raw data, processed objects, results folders \u2502 \u251c\u2500\u2500 rawdata/ \u2502 \u251c\u2500\u2500 procdata/ \u2502 \u2514\u2500\u2500 results/ \u2502 \u251c\u2500\u2500 local/ \u2502 \u251c\u2500\u2500 global/ \u2502 \u2514\u2500\u2500 validation/ \u251c\u2500\u2500 workflow/scripts/ # R and Python scripts for modeling \u2502 \u251c\u2500\u2500 Compute_GeneSigScore.r \u2502 \u251c\u2500\u2500 Create_train_set.r \u2502 \u251c\u2500\u2500 Train_Distributed_XGBoost.r \u2502 \u251c\u2500\u2500 Aggregate_model.py \u2502 \u2514\u2500\u2500 Validate_global_model.r \u251c\u2500\u2500 docs/ # Markdown-based documentation \u251c\u2500\u2500 pixi.toml # Pixi environment specification \u2514\u2500\u2500 README.md # Project overview and setup instructions","title":"Repository Structure"},{"location":"#set-up","text":"","title":"Set Up"},{"location":"#prerequisites","text":"Pixi is required to run this project. If you haven't installed it yet, follow these instructions","title":"Prerequisites"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#clone-and-run","text":"git clone https://github.com/bhklab/PredictIO-MV-Dist.git cd PredictIO-MV-Dist","title":"Clone and Run"},{"location":"#documentation","text":"Full documentation will be available in the docs/ folder or via published GitHub Pages. For data download and processing, please refer to the multivariable repository: \ud83d\udd17 https://github.com/bhklab/PredictIO-MV-Dist","title":"Documentation"},{"location":"data_sources/","text":"Data Sources Overview This document describes all Immuno-Oncology (IO) and RNA-based signature datasets used throughout the distributed univariable and multivariable analysis pipelines. Complete documentation ensures reproducibility , proper attribution, and transparency across all collaborating centers. Immuno-Oncology Data Sources RNA-Seq and Clinical Data Name : Immune Checkpoint Blockade - RNA-Seq, and Clinical data URL : https://www.orcestra.ca/clinical_icb Access Method : Direct download or programmatic retrieval via API (if applicable) Data Format : MultiAssayExperiment and SummarizedExperiment in R (Bioconductor) Citation : Bareche, Y., Kelly, D., Abbas-Aghababazadeh, F. et al., Annals of Oncology 2022 Private Cohorts Used for Model Validation Additional datasets from institutional collaborations were used only for external validation . These cohorts are not publicly available and are governed by data-sharing agreements. Dataset Name PMID Access Hartwig 31645765 Hartwig Medical Foundation IMmotion150 29867230 EGAD00001004183 INSPIRE 30867072 EGAS00001003280 OAK 27979383 EGAC00001002120 POPLAR 26970723 EGAC00001002120 RNA-Based Signature Sets Name : SignatureSets: An R Package for RNA-Based Immuno-Oncology Signatures Version : v1.0 URL - IO Signatures : bhklab/SignatureSets URL - TME Signatures : IOBR Project Access Method : Direct download or programmatic retrieval via API (if applicable) Data Format : rda, CSV (signatures, metadata) Citation : Bareche, Y., Kelly, D., Abbas-Aghababazadeh, F. et al., Annals of Oncology 2022 Key Clinical Variables Variable Description Format Example patientid Unique patient identifier string GSE12345_P01 age Age at diagnosis integer 63 sex Biological sex factor M/F cancer_type Primary cancer type string Melanoma histo Histological classification string Melanoma treatment_type IO therapy category string PD-1/PD-L1 stage Tumor stage at diagnosis string Stage II recist RECIST clinical response factor CR/PR/SD/PD response Clinical benefit status (e.g., response) string R/NR survival_time_os Overall survival time (months) numeric 21.3 event_occurred_os Overall survival event (1 = death) binary 1 survival_time_pfs Progression-free survival time (months) numeric 18.2 event_occurred_pfs Progression-free survival event (1 = progression) binary 1 survival_unit Unit of survival time string months","title":"Data Sources"},{"location":"data_sources/#data-sources","text":"","title":"Data Sources"},{"location":"data_sources/#overview","text":"This document describes all Immuno-Oncology (IO) and RNA-based signature datasets used throughout the distributed univariable and multivariable analysis pipelines. Complete documentation ensures reproducibility , proper attribution, and transparency across all collaborating centers.","title":"Overview"},{"location":"data_sources/#immuno-oncology-data-sources","text":"","title":"Immuno-Oncology Data Sources"},{"location":"data_sources/#rna-seq-and-clinical-data","text":"Name : Immune Checkpoint Blockade - RNA-Seq, and Clinical data URL : https://www.orcestra.ca/clinical_icb Access Method : Direct download or programmatic retrieval via API (if applicable) Data Format : MultiAssayExperiment and SummarizedExperiment in R (Bioconductor) Citation : Bareche, Y., Kelly, D., Abbas-Aghababazadeh, F. et al., Annals of Oncology 2022","title":"RNA-Seq and Clinical Data"},{"location":"data_sources/#private-cohorts-used-for-model-validation","text":"Additional datasets from institutional collaborations were used only for external validation . These cohorts are not publicly available and are governed by data-sharing agreements. Dataset Name PMID Access Hartwig 31645765 Hartwig Medical Foundation IMmotion150 29867230 EGAD00001004183 INSPIRE 30867072 EGAS00001003280 OAK 27979383 EGAC00001002120 POPLAR 26970723 EGAC00001002120","title":"Private Cohorts Used for Model Validation"},{"location":"data_sources/#rna-based-signature-sets","text":"Name : SignatureSets: An R Package for RNA-Based Immuno-Oncology Signatures Version : v1.0 URL - IO Signatures : bhklab/SignatureSets URL - TME Signatures : IOBR Project Access Method : Direct download or programmatic retrieval via API (if applicable) Data Format : rda, CSV (signatures, metadata) Citation : Bareche, Y., Kelly, D., Abbas-Aghababazadeh, F. et al., Annals of Oncology 2022","title":"RNA-Based Signature Sets"},{"location":"data_sources/#key-clinical-variables","text":"Variable Description Format Example patientid Unique patient identifier string GSE12345_P01 age Age at diagnosis integer 63 sex Biological sex factor M/F cancer_type Primary cancer type string Melanoma histo Histological classification string Melanoma treatment_type IO therapy category string PD-1/PD-L1 stage Tumor stage at diagnosis string Stage II recist RECIST clinical response factor CR/PR/SD/PD response Clinical benefit status (e.g., response) string R/NR survival_time_os Overall survival time (months) numeric 21.3 event_occurred_os Overall survival event (1 = death) binary 1 survival_time_pfs Progression-free survival time (months) numeric 18.2 event_occurred_pfs Progression-free survival event (1 = progression) binary 1 survival_unit Unit of survival time string months","title":"Key Clinical Variables"},{"location":"usage/","text":"Usage Guide \u2013 Distributed Multivariable Pipeline This guide outlines how to run the multivariable biomarker discovery pipeline across distributed datasets using Spark and XGBoost. Overview This pipeline supports distributed model training using Spark and script-based aggregation and validation. The primary components include: Gene signature score computation Train set generation Distributed XGBoost training Model aggregation Final validation Required Scripts All scripts are located in workflow/scripts/ : Compute_GeneSigScore.r Computes gene signature scores (e.g., GSVA, ssGSEA, weighted mean) for each dataset. Create_train_set.r Prepares training matrices by merging signature scores and patient responses for each dataset. \u279c Output: .csv files saved in data/procdata/ Train_Distributed_XGBoost.r Trains local XGBoost models on each dataset using Spark. Performs grid search for hyperparameter tuning. \u279c Output: .rds models and .csv feature importance files saved in data/results/local/ Aggregate_model.py Merges all local XGBoost models into a single global model using a tree-based bagging strategy. \u279c Output: .model and .json files saved in data/results/global/ Validate_global_model.r Evaluates the final global model on external validation datasets (private). \u279c Output: Prediction metrics saved in data/results/validation/ Input Preparation Processed input .rda files must be generated before running the multivariable pipeline. These files can be created using the univariable pipeline or downloaded directly. For full preprocessing instructions, visit: \ud83d\udd17 PredictIO-UV-Dist Required files in data/rawdata/ : Dataset files: *.rda Signature metadata: signature.rda sig.info.rda Or: Zenodo Precompiled Signatures Steps to Run the Pipeline Step 1: Compute Signature Scores Rscript workflow/scripts/Compute_GeneSigScore.r Step 2: Create Train Sets Rscript workflow/scripts/Create_train_set.r Step 3: Train Local Models with Spark Rscript workflow/scripts/Train_Distributed_XGBoost.r \ud83d\udca1 Spark must be configured locally. Make sure SPARK_HOME , HADOOP_HOME , and winutils.exe are correctly set. Step 4: Aggregate Local Models python workflow/scripts/Aggregate_model.py Step 5: Validate Global Model Rscript workflow/scripts/Validate_global_model.r Output Directory Structure /data/results/ \u251c\u2500\u2500 local/ # Per-dataset model outputs \u251c\u2500\u2500 global/ # Final aggregated model \u2514\u2500\u2500 validation/ # Results from external validation cohorts Additional Notes This is a federated analysis pipeline : no raw data sharing between centers. External validation is performed using private cohorts . All outputs are de-identified and summarized for model integration and evaluation.","title":"Usage"},{"location":"usage/#usage-guide-distributed-multivariable-pipeline","text":"This guide outlines how to run the multivariable biomarker discovery pipeline across distributed datasets using Spark and XGBoost.","title":"Usage Guide \u2013 Distributed Multivariable Pipeline"},{"location":"usage/#overview","text":"This pipeline supports distributed model training using Spark and script-based aggregation and validation. The primary components include: Gene signature score computation Train set generation Distributed XGBoost training Model aggregation Final validation","title":"Overview"},{"location":"usage/#required-scripts","text":"All scripts are located in workflow/scripts/ : Compute_GeneSigScore.r Computes gene signature scores (e.g., GSVA, ssGSEA, weighted mean) for each dataset. Create_train_set.r Prepares training matrices by merging signature scores and patient responses for each dataset. \u279c Output: .csv files saved in data/procdata/ Train_Distributed_XGBoost.r Trains local XGBoost models on each dataset using Spark. Performs grid search for hyperparameter tuning. \u279c Output: .rds models and .csv feature importance files saved in data/results/local/ Aggregate_model.py Merges all local XGBoost models into a single global model using a tree-based bagging strategy. \u279c Output: .model and .json files saved in data/results/global/ Validate_global_model.r Evaluates the final global model on external validation datasets (private). \u279c Output: Prediction metrics saved in data/results/validation/","title":"Required Scripts"},{"location":"usage/#input-preparation","text":"Processed input .rda files must be generated before running the multivariable pipeline. These files can be created using the univariable pipeline or downloaded directly. For full preprocessing instructions, visit: \ud83d\udd17 PredictIO-UV-Dist Required files in data/rawdata/ : Dataset files: *.rda Signature metadata: signature.rda sig.info.rda Or: Zenodo Precompiled Signatures","title":"Input Preparation"},{"location":"usage/#steps-to-run-the-pipeline","text":"","title":"Steps to Run the Pipeline"},{"location":"usage/#step-1-compute-signature-scores","text":"Rscript workflow/scripts/Compute_GeneSigScore.r","title":"Step 1: Compute Signature Scores"},{"location":"usage/#step-2-create-train-sets","text":"Rscript workflow/scripts/Create_train_set.r","title":"Step 2: Create Train Sets"},{"location":"usage/#step-3-train-local-models-with-spark","text":"Rscript workflow/scripts/Train_Distributed_XGBoost.r \ud83d\udca1 Spark must be configured locally. Make sure SPARK_HOME , HADOOP_HOME , and winutils.exe are correctly set.","title":"Step 3: Train Local Models with Spark"},{"location":"usage/#step-4-aggregate-local-models","text":"python workflow/scripts/Aggregate_model.py","title":"Step 4: Aggregate Local Models"},{"location":"usage/#step-5-validate-global-model","text":"Rscript workflow/scripts/Validate_global_model.r","title":"Step 5: Validate Global Model"},{"location":"usage/#output-directory-structure","text":"/data/results/ \u251c\u2500\u2500 local/ # Per-dataset model outputs \u251c\u2500\u2500 global/ # Final aggregated model \u2514\u2500\u2500 validation/ # Results from external validation cohorts","title":"Output Directory Structure"},{"location":"usage/#additional-notes","text":"This is a federated analysis pipeline : no raw data sharing between centers. External validation is performed using private cohorts . All outputs are de-identified and summarized for model integration and evaluation.","title":"Additional Notes"}]}